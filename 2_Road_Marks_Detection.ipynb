{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a77e08ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from skimage.restoration import denoise_nl_means, estimate_sigma\n",
    "from skimage.segmentation import random_walker\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from skimage.filters import threshold_multiotsu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea1e830",
   "metadata": {},
   "source": [
    "# Bird Eye View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a9d9d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_top_view(img, img_size, flags=cv2.INTER_LINEAR):\n",
    "\n",
    "    src = np.float32([(350, int(2*img.shape[0]/3)+55),     # top-left\n",
    "                       (100, img.shape[0]-100),     # bottom-left\n",
    "                       (img.shape[1]-100, img.shape[0]-100),    # bottom-right\n",
    "                       (img.shape[1]-350, int(2*img.shape[0]/3)+55)])    # top-right\n",
    "\n",
    "\n",
    "    dst = np.float32([(350,0),     # top-left\n",
    "                       (100, img.shape[0]),     # bottom-left\n",
    "                       (img.shape[1]-100, img.shape[0]),    # bottom-right\n",
    "                       (img.shape[1]-350, 0)]) # top-right\n",
    "\n",
    "    \n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    \n",
    "    return cv2.warpPerspective(img, M, img_size, flags=flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bffeec09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lane_top_view(img, img_size, flags=cv2.INTER_LINEAR):\n",
    "\n",
    "    src = np.float32([(300, 600),     # top-left\n",
    "                       (300, img.shape[0]-70),     # bottom-left\n",
    "                       (900, img.shape[0]-70),    # bottom-right\n",
    "                       (900, 600)])    # top-right\n",
    "\n",
    "    dst = np.float32([(150, 0),     # top-left\n",
    "                       (150, img.shape[0]-70),     # bottom-left\n",
    "                       (1000, img.shape[0]-70),    # bottom-right\n",
    "                       (1000, 0)])    # top-right\n",
    "\n",
    "    \n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    \n",
    "    return cv2.warpPerspective(img, M, img_size, flags=flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd38e9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in np.arange(1,2253, 30):\n",
    "#     print(i)\n",
    "img = cv2.imread('IMAGE PATH')\n",
    "mask=img.copy()\n",
    "mask[:int(2*mask.shape[0]/3)+50,:]=0\n",
    "total_view=total_top_view(mask, img_size=(mask.shape[1],mask.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "total_view = cv2.convertScaleAbs(total_view, alpha=2, beta=25)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20, 20))\n",
    "ax[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "ax[0].set_title('orginal image')\n",
    "\n",
    "ax[1].imshow(cv2.cvtColor(total_view, cv2.COLOR_BGR2RGB))\n",
    "ax[1].set_title('total_view')\n",
    "\n",
    "lane_view=lane_top_view(mask, img_size=(mask.shape[1],mask.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "lane_view = cv2.convertScaleAbs(lane_view, alpha=2, beta=25)\n",
    "\n",
    "ax[2].imshow(cv2.cvtColor(lane_view, cv2.COLOR_BGR2RGB))\n",
    "ax[2].set_title('lane_view')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70d325e",
   "metadata": {},
   "source": [
    "# Road-Marks Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69486e6",
   "metadata": {},
   "source": [
    "### Canny method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd2d89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny(img,d,u):\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    kernel = 3\n",
    "    blur = cv2.GaussianBlur(gray,(kernel, kernel),0)\n",
    "    canny = cv2.Canny(blur, d, u)\n",
    "    kernel =np.ones((3, 3),np.uint8)\n",
    "#     canny = cv2.erode(canny, kernel, iterations=5)\n",
    "    canny = cv2.dilate(canny, kernel, iterations=1)\n",
    "\n",
    "    return canny\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a97c8ac",
   "metadata": {},
   "source": [
    "### Histogram classifier & Random walker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3216d15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(top_view,image,n_class):\n",
    "    sigma_est = np.mean(estimate_sigma(top_view, multichannel=True))\n",
    "    denoise_img = denoise_nl_means(top_view, h=1.15 * sigma_est, fast_mode=True, \n",
    "                       patch_size=5, patch_distance=3, multichannel=True)\n",
    "\n",
    "\n",
    "    image = (exposure.equalize_adapthist(denoise_img))\n",
    "\n",
    "    thresholds = threshold_multiotsu(image, classes=n_class)\n",
    "\n",
    "\n",
    "    \n",
    "    regions = np.digitize(image, bins=thresholds)\n",
    "    \n",
    "    regions = random_walker(image, regions+1, beta=10, mode='bf')\n",
    "    output =(255*(regions/(n_class))).astype(np.uint8)  #Convert 64 bit integer values to uint8\n",
    "\n",
    "    gray = cv2.cvtColor(output, cv2.COLOR_BGR2GRAY)\n",
    "    _, output = cv2.threshold(gray, 170, 255, cv2.THRESH_BINARY)\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    \n",
    "    output = cv2.erode(output, kernel, iterations=2)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b4c08a",
   "metadata": {},
   "source": [
    "### Lab color model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc91f233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in np.arange(1,89,5):\n",
    "#     print(i)\n",
    "image = cv2.imread('IMAGE PATH')\n",
    "\n",
    "mask=image.copy()\n",
    "mask[:int(2*mask.shape[0]/3),:]=0\n",
    "mask[1000:,:]=0\n",
    "top_view=tr_top_view(mask, img_size=(mask.shape[1],mask.shape[0]), flags=cv2.INTER_LINEAR)   \n",
    "\n",
    "top_view1 = cv2.convertScaleAbs(top_view, alpha=2, beta=20)\n",
    "top_view1=cv2.cvtColor(top_view1, cv2.COLOR_BGR2Lab)\n",
    "L,a,b = cv2.split(top_view1)\n",
    "L = cv2.convertScaleAbs(L, alpha=1, beta=100)\n",
    "fig, ax = plt.subplots(1, 4, figsize=(20, 3))\n",
    "ax[0].hist(L.ravel(), bins=255,color='blue')\n",
    "ax[0].set_title('L')\n",
    "Lthresholds = threshold_multiotsu(L, classes=3)\n",
    "for thresh in Lthresholds:\n",
    "    ax[0].axvline(thresh, color='black')\n",
    "\n",
    "ax[1].hist(a.ravel(), bins=255,color='red')\n",
    "ax[1].set_title('a')\n",
    "athresholds = threshold_multiotsu(a, classes=3)\n",
    "for thresh in athresholds:\n",
    "    ax[1].axvline(thresh, color='black')\n",
    "\n",
    "ax[2].hist(b.ravel(), bins=255,color='green')\n",
    "ax[2].set_title('b')\n",
    "bthresholds = threshold_multiotsu(b, classes=3)\n",
    "for thresh in bthresholds:\n",
    "    ax[2].axvline(thresh, color='black')\n",
    "\n",
    "ax[3].hist(top_view1.ravel(), bins=255,color='green')\n",
    "ax[3].set_title('b')\n",
    "labthresholds = threshold_multiotsu(top_view1, classes=3)\n",
    "for thresh in labthresholds:\n",
    "    ax[3].axvline(thresh, color='black')\n",
    "plt.show()     \n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(20, 3))\n",
    "#     _, output = cv2.threshold(L, 1.1*Lthresholds[0], 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "ax[0].imshow(L,cmap='gray')\n",
    "ax[0].set_title('L')\n",
    "ax[0].axis('off')\n",
    "\n",
    "#     _, output = cv2.threshold(a, 1.1*athresholds[0], 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "ax[1].imshow(a,cmap='gray')\n",
    "ax[1].set_title('a')\n",
    "ax[1].axis('off')\n",
    "\n",
    "#     _, output = cv2.threshold(b, 1.1*bthresholds[-1], 255, cv2.THRESH_BINARY)\n",
    "\n",
    "ax[2].imshow(b,cmap='gray')\n",
    "ax[2].set_title('b')\n",
    "ax[2].axis('off')\n",
    "\n",
    "ax[3].imshow(top_view1,cmap='gray')\n",
    "ax[3].set_title('lab')\n",
    "ax[3].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4ff57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kernel = np.ones((3, 3), np.uint8)  \n",
    "# for i in np.arange(1,89,5):\n",
    "#     print(i)\n",
    "image = cv2.imread('IMAGE PATH')\n",
    "\n",
    "mask=image.copy()\n",
    "mask[:int(2*mask.shape[0]/3),:]=0\n",
    "mask[1000:,:]=0\n",
    "top_view=tr_top_view(mask, img_size=(mask.shape[1],mask.shape[0]), flags=cv2.INTER_LINEAR)   \n",
    "\n",
    "top_view1=cv2.cvtColor(top_view, cv2.COLOR_BGR2Lab)\n",
    "L,a,b = cv2.split(top_view1)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(20, 3))\n",
    "\n",
    "ax[0].hist(L.ravel(), bins=255,color='green')\n",
    "ax[0].set_title('lightness histogram')\n",
    "Lthresholds = threshold_multiotsu(L, classes=4)\n",
    "#     for thresh in Lthresholds:\n",
    "#         ax[0].axvline(thresh, color='black')\n",
    "\n",
    "\n",
    "b=b/b.max()\n",
    "cax = ax[1].imshow(b, cmap='hot', interpolation='nearest')\n",
    "fig.colorbar(cax)\n",
    "\n",
    "threshold1, white_mark = cv2.threshold(L,Lthresholds[-1], 1, cv2.THRESH_BINARY)\n",
    "#     threshold1, white_mark = cv2.threshold(L, 100, 255, cv2.THRESH_BINARY + \n",
    "#                                             cv2.THRESH_OTSU)\n",
    "ax[0].axvline(Lthresholds[-1], color='red',lw=3)\n",
    "#     threshold2, yellow_mark = cv2.threshold(b,bthresholds[-1], 1, cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "\n",
    "# Threshold the image to get only \"yellow\" colors\n",
    "yellow_mark = b.copy()\n",
    "yellow_mark[yellow_mark>0.95]=255\n",
    "yellow_mark[yellow_mark!=255]=0\n",
    "threshold2, yellow_mark = cv2.threshold(yellow_mark,bthresholds[-1], 1, cv2.THRESH_BINARY)\n",
    "#     yellow_mark = cv2.erode(yellow_mark, kernel, iterations=10)\n",
    "#     yellow_mark = cv2.dilate(yellow_mark, kernel, iterations=10)\n",
    "output = white_mark + yellow_mark\n",
    "#     output = cv2.erode(output, kernel, iterations=10)\n",
    "#     output = cv2.dilate(output, kernel, iterations=1)\n",
    "\n",
    "ax[2].imshow(white_mark,cmap='gray')\n",
    "ax[2].set_title('road marks - lightness')\n",
    "ax[2].axis('off')\n",
    "\n",
    "\n",
    "ax[3].imshow(yellow_mark,cmap='gray')\n",
    "ax[3].set_title('road marks - yellowness')\n",
    "ax[3].axis('off')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a41863",
   "metadata": {},
   "source": [
    "### Hsv color model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b2f616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in np.arange(1,89,5):\n",
    "#     print(i)\n",
    "image = cv2.imread('IMAGE PATH')\n",
    "\n",
    "mask=image.copy()\n",
    "mask[:int(2*mask.shape[0]/3),:]=0\n",
    "mask[1000:,:]=0\n",
    "top_view=tr_top_view(mask, img_size=(mask.shape[1],mask.shape[0]), flags=cv2.INTER_LINEAR)   \n",
    "\n",
    "top_view1 = cv2.convertScaleAbs(top_view, alpha=2, beta=20)\n",
    "#     top_view1 = cv2.bilateralFilter(top_view1,45,10,10)\n",
    "top_view1=cv2.cvtColor(top_view1, cv2.COLOR_BGR2HSV)\n",
    "H,S,V = cv2.split(top_view1)\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20, 3))\n",
    "ax[0].hist(H.ravel(), bins=255,color='blue')\n",
    "ax[0].set_title('H')\n",
    "Hthresholds = threshold_multiotsu(H, classes=3)\n",
    "for thresh in Hthresholds:\n",
    "    ax[0].axvline(thresh, color='black')\n",
    "\n",
    "ax[1].hist(S.ravel(), bins=255,color='red')\n",
    "ax[1].set_title('S')\n",
    "Sthresholds = threshold_multiotsu(S, classes=5)\n",
    "for thresh in Sthresholds:\n",
    "    ax[1].axvline(thresh, color='black')\n",
    "\n",
    "ax[2].hist(V.ravel(), bins=255,color='green')\n",
    "ax[2].set_title('V')\n",
    "Vthresholds = threshold_multiotsu(V, classes=3)\n",
    "for thresh in Vthresholds:\n",
    "    ax[2].axvline(thresh, color='black')\n",
    "\n",
    "plt.show()     \n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20, 3))\n",
    "_, output = cv2.threshold(H, 1.1*Hthresholds[0], 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "ax[0].imshow(output,cmap='gray')\n",
    "ax[0].set_title('top_view')\n",
    "ax[0].axis('off')\n",
    "\n",
    "_, output = cv2.threshold(S, 1.1*Sthresholds[0], 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "ax[1].imshow(output,cmap='gray')\n",
    "ax[1].set_title('top_view')\n",
    "ax[1].axis('off')\n",
    "\n",
    "_, output = cv2.threshold(V, 1.1*Vthresholds[-1], 255, cv2.THRESH_BINARY)\n",
    "\n",
    "ax[2].imshow(output,cmap='gray')\n",
    "ax[2].set_title('top_view')\n",
    "ax[2].axis('off')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc1c567",
   "metadata": {},
   "source": [
    "### YCrCb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deae95b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in np.arange(1,89,5):\n",
    "#     print(i)\n",
    "image = cv2.imread('IMAGE PATH')\n",
    "\n",
    "mask=image.copy()\n",
    "mask[:int(2*mask.shape[0]/3),:]=0\n",
    "mask[1000:,:]=0\n",
    "top_view=tr_top_view(mask, img_size=(mask.shape[1],mask.shape[0]), flags=cv2.INTER_LINEAR)   \n",
    "\n",
    "top_view1 = cv2.convertScaleAbs(top_view, alpha=2, beta=20)\n",
    "top_view1=cv2.cvtColor(top_view1, cv2.COLOR_BGR2YCrCb)\n",
    "Y,Cr,Cb = cv2.split(top_view1)\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20, 3))\n",
    "ax[0].hist(Y.ravel(), bins=255,color='blue')\n",
    "ax[0].set_title('Y')\n",
    "Ythresholds = threshold_multiotsu(Y, classes=3)\n",
    "for thresh in Ythresholds:\n",
    "    ax[0].axvline(thresh, color='black')\n",
    "\n",
    "ax[1].hist(Cr.ravel(), bins=255,color='red')\n",
    "ax[1].set_title('Cr')\n",
    "Crthresholds = threshold_multiotsu(Cr, classes=5)\n",
    "for thresh in Crthresholds:\n",
    "    ax[1].axvline(thresh, color='black')\n",
    "\n",
    "ax[2].hist(Cb.ravel(), bins=255,color='green')\n",
    "ax[2].set_title('Cb')\n",
    "Cbthresholds = threshold_multiotsu(Cb, classes=3)\n",
    "for thresh in Cbthresholds:\n",
    "    ax[2].axvline(thresh, color='black')\n",
    "\n",
    "plt.show()     \n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20, 3))\n",
    "ax[0].imshow(Y,cmap='gray')\n",
    "ax[0].set_title('top_view')\n",
    "ax[0].axis('off')\n",
    "\n",
    "_, output = cv2.threshold(Cr, Crthresholds[-1], 255, cv2.THRESH_BINARY)\n",
    "\n",
    "ax[1].imshow(output,cmap='gray')\n",
    "ax[1].set_title('top_view')\n",
    "ax[1].axis('off')\n",
    "\n",
    "\n",
    "ax[2].imshow(Cb,cmap='gray')\n",
    "ax[2].set_title('top_view')\n",
    "ax[2].axis('off')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e369ba",
   "metadata": {},
   "source": [
    "### Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9fea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in np.arange(1,2253, 30):\n",
    "#     print(i)\n",
    "img = cv2.imread('IMAGE PATH')\n",
    "total_view=total_top_view(img, img_size=(img.shape[1],img.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "contrast_total_view = cv2.convertScaleAbs(total_view, alpha=2, beta=25)\n",
    "\n",
    "fig, ax = plt.subplots(1, 5, figsize=(20, 20))\n",
    "plt.subplots_adjust(wspace=0.1)\n",
    "ax[0].imshow(cv2.cvtColor(contrast_total_view, cv2.COLOR_BGR2RGB))\n",
    "ax[0].set_title('orginal image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "canny_marks=canny(contrast_total_view, 50, 80)\n",
    "\n",
    "ax[1].imshow(cv2.cvtColor(canny_marks, cv2.COLOR_BGR2RGB))\n",
    "ax[1].set_title('canny method')\n",
    "ax[1].axis('off')\n",
    "\n",
    "image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "image = image.astype(np.float64) / 255.0\n",
    "hist_total_view=total_top_view(image, img_size=(image.shape[1],image.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "hist_total_view = cv2.convertScaleAbs(hist_total_view, alpha=100, beta=100)\n",
    "hist_marks=run(hist_total_view,image,3)\n",
    "\n",
    "ax[2].imshow(cv2.cvtColor(hist_marks, cv2.COLOR_BGR2RGB))\n",
    "ax[2].set_title('histogram method')\n",
    "ax[2].axis('off')\n",
    "\n",
    "\n",
    "lab=cv2.cvtColor(total_view, cv2.COLOR_BGR2Lab)\n",
    "L,a,b = cv2.split(lab)\n",
    "Lthresholds = threshold_multiotsu(L, classes=4)\n",
    "th, Lwhite_mark = cv2.threshold(L,Lthresholds[-1], 1, cv2.THRESH_BINARY)\n",
    "\n",
    "ax[3].imshow(Lwhite_mark,cmap='gray')\n",
    "ax[3].set_title('Lightness - Lab')\n",
    "ax[3].axis('off')\n",
    "\n",
    "\n",
    "contrast_view = cv2.convertScaleAbs(total_view, alpha=2, beta=20)\n",
    "hsv=cv2.cvtColor(contrast_view, cv2.COLOR_BGR2HSV)\n",
    "h,s,v = cv2.split(contrast_view)\n",
    "\n",
    "\n",
    "Vthresholds = threshold_multiotsu(v, classes=3)\n",
    "th, Vwhite_mark = cv2.threshold(v,Vthresholds[-1], 1, cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "ax[4].imshow(Vwhite_mark,cmap='gray')\n",
    "ax[4].set_title('Value - HSV')\n",
    "ax[4].axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c72cc49",
   "metadata": {},
   "source": [
    "# Lane-Marks Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2357fe",
   "metadata": {},
   "source": [
    "### Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da311fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobel_filters(img):\n",
    "    Kx = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], np.float32)\n",
    "    Ky = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], np.float32)\n",
    "    \n",
    "    Ix = cv2.filter2D(src=img, ddepth=-1, kernel=Kx)\n",
    "    Iy = cv2.filter2D(src=img, ddepth=-1, kernel=Ky)\n",
    "    \n",
    "    G = np.hypot(Ix, Iy)\n",
    "    G = G / G.max() * 255\n",
    "    theta = np.arctan2(Iy, Ix)\n",
    "    \n",
    "    return (G.astype(np.uint8), theta)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for i in np.arange(1,2253, 30):\n",
    "#     print(i)\n",
    "img = cv2.imread('IMAGE PATH')\n",
    "total_view=lane_top_view(img, img_size=(img.shape[1],img.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "contrast_total_view = cv2.convertScaleAbs(total_view, alpha=2, beta=25)\n",
    "\n",
    "fig, ax = plt.subplots(1, 5, figsize=(20, 20))\n",
    "plt.subplots_adjust(wspace=0.1)\n",
    "ax[0].imshow(cv2.cvtColor(contrast_total_view, cv2.COLOR_BGR2RGB))\n",
    "ax[0].set_title('orginal image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "G, theta=sobel_filters(contrast_total_view)\n",
    "\n",
    "\n",
    "flattened_arr = G.flatten()\n",
    "low_tr = np.quantile(flattened_arr, 0.95)\n",
    "high_tr = np.quantile(flattened_arr, 0.99)\n",
    "canny_marks=canny(contrast_total_view,low_tr,high_tr)\n",
    "\n",
    "ax[1].imshow(cv2.cvtColor(canny_marks, cv2.COLOR_BGR2RGB))\n",
    "ax[1].set_title('canny method')\n",
    "ax[1].axis('off')\n",
    "\n",
    "image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "image = image.astype(np.float64) / 255.0\n",
    "hist_total_view=lane_top_view(image, img_size=(image.shape[1],image.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "hist_total_view = cv2.convertScaleAbs(hist_total_view, alpha=100, beta=100)\n",
    "hist_marks=run(hist_total_view,image,3)\n",
    "\n",
    "ax[2].imshow(cv2.cvtColor(hist_marks, cv2.COLOR_BGR2RGB))\n",
    "ax[2].set_title('histogram method')\n",
    "ax[2].axis('off')\n",
    "\n",
    "\n",
    "lab=cv2.cvtColor(total_view, cv2.COLOR_BGR2Lab)\n",
    "L,a,b = cv2.split(lab)\n",
    "Lthresholds = threshold_multiotsu(L, classes=4)\n",
    "th, Lwhite_mark = cv2.threshold(L,Lthresholds[-1], 1, cv2.THRESH_BINARY)\n",
    "\n",
    "ax[3].imshow(Lwhite_mark,cmap='gray')\n",
    "ax[3].set_title('Lightness - Lab')\n",
    "ax[3].axis('off')\n",
    "\n",
    "\n",
    "contrast_view = cv2.convertScaleAbs(total_view, alpha=2, beta=20)\n",
    "hsv=cv2.cvtColor(contrast_view, cv2.COLOR_BGR2HSV)\n",
    "h,s,v = cv2.split(contrast_view)\n",
    "\n",
    "\n",
    "Vthresholds = threshold_multiotsu(v, classes=3)\n",
    "th, Vwhite_mark = cv2.threshold(v,Vthresholds[-1], 1, cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "ax[4].imshow(Vwhite_mark,cmap='gray')\n",
    "ax[4].set_title('Value - HSV')\n",
    "ax[4].axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcf25db",
   "metadata": {},
   "source": [
    "# Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01ceffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lane_top_view(img, img_size, flags=cv2.INTER_LINEAR):\n",
    "\n",
    "    src = np.float32([(300, 600),     # top-left\n",
    "                       (300, img.shape[0]-70),     # bottom-left\n",
    "                       (900, img.shape[0]-70),    # bottom-right\n",
    "                       (900, 600)])    # top-right\n",
    "\n",
    "    dst = np.float32([(150, 0),     # top-left\n",
    "                       (150, img.shape[0]-70),     # bottom-left\n",
    "                       (1000, img.shape[0]-70),    # bottom-right\n",
    "                       (1000, 0)])    # top-right\n",
    "\n",
    "    \n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    \n",
    "    return cv2.warpPerspective(img, M, img_size, flags=flags)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def tr_back_view(img, img_size, flags=cv2.INTER_LINEAR):\n",
    "\n",
    "    src = np.float32([(300, 600),     # top-left\n",
    "                       (300, img.shape[0]-70),     # bottom-left\n",
    "                       (900, img.shape[0]-70),    # bottom-right\n",
    "                       (900, 600)])    # top-right\n",
    "\n",
    "    dst = np.float32([(150, 0),     # top-left\n",
    "                       (150, img.shape[0]-70),     # bottom-left\n",
    "                       (1000, img.shape[0]-70),    # bottom-right\n",
    "                       (1000, 0)])    # top-right\n",
    "\n",
    "    \n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "\n",
    "    M_inv = cv2.getPerspectiveTransform(dst, src)\n",
    "    \n",
    "    return cv2.warpPerspective(img, M_inv, img_size, flags=flags)\n",
    "\n",
    "    \n",
    "\n",
    "def canny(img,d,u):\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    kernel = 3\n",
    "    blur = cv2.GaussianBlur(gray,(kernel, kernel),0)\n",
    "    canny = cv2.Canny(blur, d, u)\n",
    "    kernel =np.ones((3, 3),np.uint8)\n",
    "    \n",
    "    canny = cv2.dilate(canny, kernel, iterations=4)\n",
    "    canny = cv2.erode(canny, kernel, iterations=2)\n",
    "    return canny\n",
    "\n",
    "\n",
    "def average_slope_intercept(image, lines):\n",
    "    left_fit    = []\n",
    "    right_fit   = []\n",
    "    if lines is None:\n",
    "        return None\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            fit = np.polyfit((x1,x2), (y1,y2), 1)\n",
    "            slope = fit[0]\n",
    "#             print(slope)\n",
    "            intercept = fit[1]\n",
    "            if slope < -5: \n",
    "                left_fit.append((slope, intercept))\n",
    "            if slope > 5:\n",
    "                right_fit.append((slope, intercept))\n",
    "    left_fit_average  = np.average(left_fit, axis=0)\n",
    "    right_fit_average = np.average(right_fit, axis=0)\n",
    "    left_line  = make_points(image, left_fit_average)\n",
    "    right_line = make_points(image, right_fit_average)\n",
    "    averaged_lines = [left_line, right_line]\n",
    "    return averaged_lines\n",
    "\n",
    "def make_points(image, line):\n",
    "    slope, intercept = line\n",
    "    y1 = int(image.shape[0])\n",
    "    y2 = int(y1*3.0/5)      \n",
    "    x1 = int((y1 - intercept)/slope)\n",
    "    x2 = int((y2 - intercept)/slope)\n",
    "    return [[x1, y1, x2, y2]]\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def region_of_interest_lane(img):\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    mask = np.zeros_like(img)\n",
    "    poly = np.array([[\n",
    "    (200,700),\n",
    "    (200, 0),\n",
    "    \n",
    "    (1000, 0),\n",
    "    (1000, 700)]], np.int32)\n",
    "    kernel =np.ones((3, 3),np.uint8)\n",
    "    cv2.fillPoly(mask, poly, (255, 255, 255))\n",
    "#     mask = cv2.erode(mask, kernel, iterations=50)\n",
    "#     mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def display_advlines(img,lines):\n",
    "    line_image = np.zeros_like(img)\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            for x1, y1, x2, y2 in line:\n",
    "                cv2.line(line_image,(x1,y1),(x2,y2),(0,0,255),10)\n",
    "    return line_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0f8a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(img , nwindows = 9):\n",
    "    # Height of of windows - based on nwindows and image shape\n",
    "    window_height = np.int(img.shape[0]//nwindows)\n",
    "\n",
    "    # Identify the x and y positions of all nonzero pixel in the image\n",
    "    nonzero = img.nonzero()\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    \n",
    "    return window_height , nwindows ,nonzero , nonzerox ,nonzeroy\n",
    "\n",
    "def pixels_in_window(center, margin, height):  \n",
    "\n",
    "    topleft = (center[0]-margin, center[1]-height//2)\n",
    "    bottomright = (center[0]+margin, center[1]+height//2)\n",
    "\n",
    "    condx = (topleft[0] <= nonzerox) & (nonzerox <= bottomright[0])\n",
    "    condy = (topleft[1] <= nonzeroy) & (nonzeroy <= bottomright[1])\n",
    "    \n",
    "    return nonzerox[condx&condy], nonzeroy[condx&condy]\n",
    "\n",
    "\n",
    "margin = 100\n",
    "minpix = 50\n",
    "\n",
    "def find_lane_pixels(img):\n",
    "\n",
    "    assert(len(img.shape) == 2)\n",
    "    out_img = np.dstack((img, img, img))\n",
    "\n",
    "    bottom_half = img[img.shape[0]//2:,:]\n",
    "    histogram = np.sum(bottom_half, axis=0)\n",
    "    midpoint = histogram.shape[0]//2\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Current position to be update later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    y_current = img.shape[0] + window_height//2\n",
    "\n",
    "    # Create empty lists to reveice left and right lane pixel\n",
    "    leftx, lefty, rightx, righty = [], [], [], []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for _ in range(nwindows):\n",
    "        y_current -= window_height\n",
    "        center_left = (leftx_current, y_current)\n",
    "        center_right = (rightx_current, y_current)\n",
    "\n",
    "        good_left_x, good_left_y = pixels_in_window(center_left, margin, window_height)\n",
    "        good_right_x, good_right_y = pixels_in_window(center_right, margin, window_height)\n",
    "\n",
    "        # Append these indices to the lists\n",
    "        leftx.extend(good_left_x)\n",
    "        lefty.extend(good_left_y)\n",
    "        rightx.extend(good_right_x)\n",
    "        righty.extend(good_right_y)\n",
    "\n",
    "        if len(good_left_x) > minpix:\n",
    "            leftx_current = np.int32(np.mean(good_left_x))\n",
    "        if len(good_right_x) > minpix:\n",
    "            rightx_current = np.int32(np.mean(good_right_x))\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "\n",
    "left_fit = None\n",
    "right_fit = None\n",
    "\n",
    "def fit_poly(img):\n",
    "\n",
    "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(img)\n",
    "\n",
    "    \n",
    "    if len(lefty) > 1500:\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    if len(righty) > 1500:\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    maxy = img.shape[0] - 1\n",
    "    miny = img.shape[0] // 3\n",
    "    \n",
    "    if len(lefty):\n",
    "        maxy = max(maxy, np.max(lefty))\n",
    "        miny = min(miny, np.min(lefty))\n",
    "\n",
    "    if len(righty):\n",
    "        maxy = max(maxy, np.max(righty))\n",
    "        miny = min(miny, np.min(righty))\n",
    "\n",
    "    ploty = np.linspace(miny, maxy, img.shape[0]-450)\n",
    "\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "#         left_fitx = left_fit[0]*ploty + left_fit[1]\n",
    "#         right_fitx = right_fit[0]*ploty + right_fit[1]\n",
    "\n",
    "        # Visualization\n",
    "        for i, y in enumerate(ploty):\n",
    "            l = int(left_fitx[i])\n",
    "            r = int(right_fitx[i])\n",
    "            y = int(y)\n",
    "            cv2.line(out_img, (l, y), (r, y), (0, 255, 0))\n",
    "\n",
    "        return out_img ,True,left_fit,right_fit\n",
    "    except:\n",
    "        return out_img ,False ,None,None\n",
    "\n",
    "\n",
    "\n",
    "def lane_top_view(img, img_size, flags=cv2.INTER_LINEAR):\n",
    "\n",
    "    src = np.float32([(300, 600),     # top-left\n",
    "                       (300, img.shape[0]-70),     # bottom-left\n",
    "                       (900, img.shape[0]-70),    # bottom-right\n",
    "                       (900, 600)])    # top-right\n",
    "\n",
    "    dst = np.float32([(150, 0),     # top-left\n",
    "                       (150, img.shape[0]-70),     # bottom-left\n",
    "                       (1000, img.shape[0]-70),    # bottom-right\n",
    "                       (1000, 0)])    # top-right\n",
    "\n",
    "    \n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    \n",
    "    return cv2.warpPerspective(img, M, img_size, flags=flags)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def lane_back_view(img, img_size, flags=cv2.INTER_LINEAR):\n",
    "\n",
    "    src = np.float32([(300, 600),     # top-left\n",
    "                       (300, img.shape[0]-70),     # bottom-left\n",
    "                       (900, img.shape[0]-70),    # bottom-right\n",
    "                       (900, 600)])    # top-right\n",
    "\n",
    "    dst = np.float32([(150, 0),     # top-left\n",
    "                       (150, img.shape[0]-70),     # bottom-left\n",
    "                       (1000, img.shape[0]-70),    # bottom-right\n",
    "                       (1000, 0)])    # top-right\n",
    "\n",
    "    \n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "\n",
    "    M_inv = cv2.getPerspectiveTransform(dst, src)\n",
    "    \n",
    "    return cv2.warpPerspective(img, M_inv, img_size, flags=flags)\n",
    "\n",
    "\n",
    "def total_top_view(img, img_size, flags=cv2.INTER_LINEAR):\n",
    "\n",
    "    src = np.float32([(350, int(2*img.shape[0]/3)+55),     # top-left\n",
    "                       (100, img.shape[0]-100),     # bottom-left\n",
    "                       (img.shape[1]-100, img.shape[0]-100),    # bottom-right\n",
    "                       (img.shape[1]-350, int(2*img.shape[0]/3)+55)])    # top-right\n",
    "\n",
    "\n",
    "    dst = np.float32([(350,0),     # top-left\n",
    "                       (100, img.shape[0]),     # bottom-left\n",
    "                       (img.shape[1]-100, img.shape[0]),    # bottom-right\n",
    "                       (img.shape[1]-350, 0)])\n",
    "\n",
    "    \n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    \n",
    "    return cv2.warpPerspective(img, M, img_size, flags=flags)\n",
    "    \n",
    "\n",
    "def total_back_view(img, img_size, flags=cv2.INTER_LINEAR):\n",
    "\n",
    "    src = np.float32([(350, int(2*img.shape[0]/3)+55),     # top-left\n",
    "                       (100, img.shape[0]-100),     # bottom-left\n",
    "                       (img.shape[1]-100, img.shape[0]-100),    # bottom-right\n",
    "                       (img.shape[1]-350, int(2*img.shape[0]/3)+55)])    # top-right\n",
    "\n",
    "\n",
    "    dst = np.float32([(350,0),     # top-left\n",
    "                       (100, img.shape[0]),     # bottom-left\n",
    "                       (img.shape[1]-100, img.shape[0]),    # bottom-right\n",
    "                       (img.shape[1]-350, 0)])\n",
    "\n",
    "    \n",
    "    \n",
    "    M_inv = cv2.getPerspectiveTransform(dst, src)\n",
    "    \n",
    "    return cv2.warpPerspective(img, M_inv, img_size, flags=flags)\n",
    "\n",
    "def sobel_filters(img):\n",
    "    Kx = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], np.float32)\n",
    "    Ky = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], np.float32)\n",
    "    \n",
    "    Ix = cv2.filter2D(src=img, ddepth=-1, kernel=Kx)\n",
    "    Iy = cv2.filter2D(src=img, ddepth=-1, kernel=Ky)\n",
    "    \n",
    "    G = np.hypot(Ix, Iy)\n",
    "    G = G / G.max() * 255\n",
    "    theta = np.arctan2(Iy, Ix)\n",
    "    \n",
    "    return (G.astype(np.uint8), theta)    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "li=[2,3,4,5,6,7,8,48, 54, 58, 155 ,190, 192 ,195 ,205, 221 ,291 ,296, 297]\n",
    "\n",
    "is_roi=False\n",
    "kernel =np.ones((3, 3),np.uint8)\n",
    "\n",
    "# keep_straight_img = mpimg.imread('straight.png')\n",
    "start=True\n",
    "# for i in tqdm(np.arange(1,2252)):\n",
    "# #     print(i)\n",
    "img = cv2.imread('IMAGE PATH')\n",
    "\n",
    "top_view=lane_top_view(img, img_size=(img.shape[1],img.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "top_view = cv2.convertScaleAbs(top_view, alpha=2, beta=25)\n",
    "\n",
    "\n",
    "G, theta=sobel_filters(top_view)\n",
    "\n",
    "\n",
    "flattened_arr = G.flatten()\n",
    "low_tr = np.quantile(flattened_arr, 0.95)\n",
    "high_tr = np.quantile(flattened_arr, 0.99)\n",
    "lane_filtered=canny(top_view,low_tr,high_tr)\n",
    "#     lab=cv2.cvtColor(top_view, cv2.COLOR_BGR2Lab)\n",
    "#     L,a,b = cv2.split(lab)\n",
    "#     Lthresholds = threshold_multiotsu(L, classes=4)\n",
    "#     th, lane_filtered = cv2.threshold(L,Lthresholds[-1], 255, cv2.THRESH_BINARY)\n",
    "\n",
    "if is_roi:\n",
    "\n",
    "    ployy = cv2.dilate(ployy, kernel, iterations=150)\n",
    "    _, roi = cv2.threshold(ployy, 170, 1, cv2.THRESH_BINARY)\n",
    "    lane_filtered =lane_filtered * roi\n",
    "window_height , nwindows ,nonzero , nonzerox ,nonzeroy = extract_features(lane_filtered , nwindows = 9)\n",
    "ployy,is_roi,left_fit,right_fit=fit_poly(lane_filtered)\n",
    "\n",
    "if not is_roi:\n",
    "    lane_filtered=canny(top_view,low_tr,high_tr)\n",
    "    window_height , nwindows ,nonzero , nonzerox ,nonzeroy = extract_features(lane_filtered , nwindows = 9)\n",
    "    ployy,is_roi,left_fit,right_fit=fit_poly(lane_filtered)\n",
    "\n",
    "\n",
    "\n",
    "ployy=ployy[:,:,1]-ployy[:,:,0]\n",
    "\n",
    "\n",
    "\n",
    "top_view=total_top_view(img, img_size=(img.shape[1],img.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "lab=cv2.cvtColor(top_view, cv2.COLOR_BGR2Lab)\n",
    "L,a,b = cv2.split(lab)\n",
    "Lthresholds = threshold_multiotsu(L, classes=4)\n",
    "th, Lwhite_mark = cv2.threshold(L,Lthresholds[-1], 255, cv2.THRESH_BINARY)\n",
    "\n",
    "contrast_view = cv2.convertScaleAbs(top_view, alpha=2, beta=20)\n",
    "hsv=cv2.cvtColor(contrast_view, cv2.COLOR_BGR2HSV)\n",
    "h,s,v = cv2.split(contrast_view)\n",
    "\n",
    "\n",
    "Vthresholds = threshold_multiotsu(v, classes=4)\n",
    "th, Vwhite_mark = cv2.threshold(v,Vthresholds[-1], 1, cv2.THRESH_BINARY)\n",
    "\n",
    "mask= Lwhite_mark + Vwhite_mark\n",
    "_ , mask=cv2.threshold(mask,0.5, 1, cv2.THRESH_BINARY)\n",
    "kernel =np.ones((3, 3),np.uint8)\n",
    "mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "raw=np.zeros_like(top_view)\n",
    "raw[mask!=0]=[0,0,255]\n",
    "back_view=total_back_view(raw, img_size=(img.shape[1],img.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "out_img = cv2.addWeighted(back_view, 1, img, 1, 0)\n",
    "\n",
    "#     print(is_roi,start,ployy.mean())\n",
    "if ployy.mean()<15:\n",
    "    out_img = cv2.addWeighted(np.stack((np.zeros_like(lastframe_back),lastframe_back,np.zeros_like(lastframe_back)), axis=-1), 1, out_img, 1, 0)\n",
    "else:\n",
    "    back_view=lane_back_view(ployy, img_size=(img.shape[1],img.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "    out_img = cv2.addWeighted(np.stack((np.zeros_like(back_view),back_view,np.zeros_like(back_view)), axis=-1), 1, out_img, 1, 0)\n",
    "    lastframe_back=back_view.copy()\n",
    "    start=False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 20))\n",
    "ax[0].imshow(cv2.cvtColor(out_img, cv2.COLOR_BGR2RGB))\n",
    "ax[1].imshow(cv2.cvtColor(lane_filtered, cv2.COLOR_BGR2RGB))\n",
    "plt.show()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37ca63a",
   "metadata": {},
   "source": [
    "# Additional Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddff58c",
   "metadata": {},
   "source": [
    "### Region Growing > Road Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1a71d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def get_neighbouring_pixels(x, y, shape):\n",
    "    neighbours = []\n",
    "    max_x = shape[1] - 1\n",
    "    max_y = shape[0] - 1\n",
    "    directions = [(-1, -1), (0, -1), (1, -1), (-1, 0), (1, 0), (-1, 1), (0, 1), (1, 1)]\n",
    "\n",
    "    for dx, dy in directions:\n",
    "        nx, ny = x + dx, y + dy\n",
    "        if 0 <= nx <= max_x and 0 <= ny <= max_y:\n",
    "            neighbours.append((nx, ny))\n",
    "\n",
    "    return neighbours\n",
    "\n",
    "\n",
    "def euclidean_distance(a, b):\n",
    "    return np.sqrt(np.sum((a-b)**2))\n",
    "\n",
    "def region_growing(img, seed, threshold):\n",
    "    seed_points = [seed]\n",
    "    out_img = np.zeros_like(img)\n",
    "    processed = []\n",
    "\n",
    "    while seed_points:\n",
    "        pix = seed_points.pop(0)\n",
    "        out_img[pix] = img[pix]\n",
    "\n",
    "        for coord in get_neighbouring_pixels(*pix, img.shape):\n",
    "            try:\n",
    "                if euclidean_distance(img[seed], img[coord]) < threshold and coord not in processed:\n",
    "                    out_img[coord] = img[coord]\n",
    "                    seed_points.append(coord)\n",
    "                    processed.append(coord)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    return out_img\n",
    "\n",
    "image = cv2.imread('IMAGE PATH')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "mask=image.copy()\n",
    "mask[:int(2*mask.shape[0]/3),:]=0\n",
    "mask[1000:,:]=0\n",
    "image=tr_top_view(mask, img_size=(mask.shape[1],mask.shape[0]), flags=cv2.INTER_LINEAR)   \n",
    "    \n",
    "image = cv2.resize(image, (0,0), fx=0.1, fy=0.1)\n",
    "seed = (50,85)\n",
    "color_threshold = 15.0  # adjust this value based on your requirements\n",
    "out = region_growing(image, seed, color_threshold)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "# cv2.imshow('image',image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "ax[0].imshow(image,cmap='gray')\n",
    "ax[1].imshow(out,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5127b098",
   "metadata": {},
   "source": [
    "### K-means Clustering > Road Marks Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c4125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "is_roi=False\n",
    "\n",
    "kernel =np.ones((3, 3),np.uint8)\n",
    "\n",
    "\n",
    "# for i in np.arange(1,2000,50):\n",
    "#     print(i)\n",
    "image = cv2.imread('IMAGE PATH')\n",
    "\n",
    "mask=image.copy()\n",
    "mask[:int(2*mask.shape[0]/3),:]=0\n",
    "mask[1000:,:]=0\n",
    "mask=tr_top_view(mask, img_size=(mask.shape[1],mask.shape[0]), flags=cv2.INTER_LINEAR)   \n",
    "\n",
    "top_view1 = cv2.convertScaleAbs(mask, alpha=2, beta=20)\n",
    "top_view1 = cv2.bilateralFilter(top_view1,45,10,10)\n",
    "top_view=cv2.cvtColor(top_view1, cv2.COLOR_BGR2HSV)\n",
    "H,S,V = cv2.split(top_view1)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 5))\n",
    "# # GaussianBlur(img,(5,5),0)\n",
    "\n",
    "ax[0].imshow(cv2.cvtColor(top_view1, cv2.COLOR_BGR2RGB))\n",
    "ax[0].set_title('top_view')\n",
    "ax[0].axis('off')\n",
    "pixel_vals = V.reshape((-1,1))\n",
    "pixel_vals = np.float32(pixel_vals)\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.85)\n",
    "retval, labels, centers = cv2.kmeans(pixel_vals, 2, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "centers = np.uint8(centers)\n",
    "segmented_data = centers[labels.flatten()]\n",
    "segmented_image = segmented_data.reshape((V.shape))\n",
    "#     ret, lane_filtered = cv2.threshold(segmented_image, 100, 255, cv2.THRESH_BINARY)\n",
    "ret, lane_filtered = cv2.threshold(segmented_image, 100, 255, cv2.THRESH_BINARY + \n",
    "                                        cv2.THRESH_OTSU)\n",
    "#     print(ret)\n",
    "#     ax[1].imshow(cv2.cvtColor(segmented_image, cv2.COLOR_BGR2RGB))\n",
    "#     ax[1].set_title('top_view')\n",
    "#     ax[1].axis('off')\n",
    "\n",
    "\n",
    "ax[1].imshow(cv2.cvtColor(lane_filtered, cv2.COLOR_BGR2RGB))\n",
    "ax[1].set_title('kmeans 2 cluster')\n",
    "ax[1].axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f68487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in np.arange(1,89,5):\n",
    "#     print(i)\n",
    "image = cv2.imread('IMAGE PATH')\n",
    "\n",
    "mask=image.copy()\n",
    "mask[:int(2*mask.shape[0]/3),:]=0\n",
    "mask[1000:,:]=0\n",
    "top_view=tr_top_view(mask, img_size=(mask.shape[1],mask.shape[0]), flags=cv2.INTER_LINEAR)   \n",
    "\n",
    "top_view = cv2.convertScaleAbs(top_view, alpha=2, beta=20)\n",
    "top_view1=cv2.cvtColor(top_view, cv2.COLOR_BGR2Lab)\n",
    "L,a,b = cv2.split(top_view1)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 5, figsize=(20, 10))\n",
    "\n",
    "ax[0].imshow(cv2.cvtColor(top_view, cv2.COLOR_BGR2RGB))\n",
    "ax[0].set_title('image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(b,cmap='gray')\n",
    "ax[1].set_title('b')\n",
    "ax[1].axis('off')\n",
    "\n",
    "\n",
    "pixel_vals = b.reshape((-1,1))\n",
    "pixel_vals = np.float32(pixel_vals)\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.85)\n",
    "retval, labels, centers = cv2.kmeans(pixel_vals, 2, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "centers = np.uint8(centers)\n",
    "segmented_data = centers[labels.flatten()]\n",
    "segmented_image = segmented_data.reshape((b.shape))\n",
    "\n",
    "ret, output = cv2.threshold(segmented_image, 100, 255, cv2.THRESH_BINARY + \n",
    "                                        cv2.THRESH_OTSU)\n",
    "ax[2].imshow(output,cmap='gray')\n",
    "ax[2].set_title('kmean - 2cluster')\n",
    "ax[2].axis('off')\n",
    "\n",
    "\n",
    "\n",
    "ret, output = cv2.threshold(b, 100, 255, cv2.THRESH_BINARY + \n",
    "                                        cv2.THRESH_OTSU)\n",
    "\n",
    "ax[3].imshow(output,cmap='gray')\n",
    "ax[3].set_title('b - THRESH_OTSU')\n",
    "ax[3].axis('off')\n",
    "\n",
    "fil,gi =run(top_view,image,2)\n",
    "ax[4].imshow(fil,cmap='gray')\n",
    "ax[4].set_title('contrast - randomwalker')\n",
    "ax[4].axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bb819c",
   "metadata": {},
   "source": [
    "### Lab color model > Road Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9c9ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in np.arange(1,89,5):\n",
    "#     print(i)\n",
    "image = cv2.imread('IMAGE PATH')\n",
    "\n",
    "mask=image.copy()\n",
    "mask[:int(2*mask.shape[0]/3),:]=0\n",
    "mask[1000:,:]=0\n",
    "top_view=tr_top_view(mask, img_size=(mask.shape[1],mask.shape[0]), flags=cv2.INTER_LINEAR)   \n",
    "\n",
    "top_view1 = cv2.convertScaleAbs(top_view, alpha=2, beta=20)\n",
    "top_view1=cv2.cvtColor(top_view1, cv2.COLOR_BGR2Lab)\n",
    "L,a,b = cv2.split(top_view1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(20, 3))\n",
    "\n",
    "ax[0].hist(b.ravel(), bins=255,color='blue')\n",
    "ax[0].set_title('b')\n",
    "bthresholds = threshold_multiotsu(b, classes=3)\n",
    "for thresh in bthresholds:\n",
    "    ax[0].axvline(thresh, color='black')\n",
    "\n",
    "ax[1].imshow(b,cmap='gray')\n",
    "ax[1].set_title('top_view')\n",
    "ax[1].axis('off')\n",
    "\n",
    "#     _, output = cv2.threshold(b, bthresholds[0], 255, cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "ret, output = cv2.threshold(b, 100, 255, cv2.THRESH_BINARY + \n",
    "                                        cv2.THRESH_OTSU)\n",
    "ax[2].imshow(output,cmap='gray')\n",
    "ax[2].set_title('top_view')\n",
    "ax[2].axis('off')\n",
    "\n",
    "ax[3].imshow(cv2.cvtColor(top_view, cv2.COLOR_BGR2RGB))\n",
    "ax[3].set_title('top_view')\n",
    "ax[3].axis('off')\n",
    "\n",
    "ax[0].axvline(ret, color='red')\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b73ad2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((3, 3), np.uint8)  \n",
    "# for i in np.arange(1,89,5):\n",
    "#     print(i)\n",
    "image = cv2.imread('IMAGE PATH')\n",
    "\n",
    "mask=image.copy()\n",
    "mask[:int(2*mask.shape[0]/3),:]=0\n",
    "mask[1000:,:]=0\n",
    "top_view=tr_top_view(mask, img_size=(mask.shape[1],mask.shape[0]), flags=cv2.INTER_LINEAR)   \n",
    "\n",
    "top_view1=cv2.cvtColor(top_view, cv2.COLOR_BGR2Lab)\n",
    "top_view1 = cv2.bilateralFilter(top_view1,45,10,10)\n",
    "L,a,b = cv2.split(top_view1)\n",
    "\n",
    "\n",
    "\n",
    "Lthresholds = threshold_multiotsu(L, classes=4)\n",
    "\n",
    "threshold1, marks = cv2.threshold(L,Lthresholds[-1], 1, cv2.THRESH_BINARY)\n",
    "\n",
    "marks = cv2.erode(marks, kernel, iterations=1)\n",
    "marks = cv2.dilate(marks, kernel, iterations=2)\n",
    "\n",
    "\n",
    "mask = cv2.dilate(marks, kernel, iterations=12)\n",
    "road_seg=top_view.copy()\n",
    "road_seg[mask!=0]=0\n",
    "road_seg=cv2.cvtColor(road_seg, cv2.COLOR_BGR2Lab)\n",
    "L,a,b = cv2.split(road_seg)\n",
    "ret, road = cv2.threshold(b, 100, 255, cv2.THRESH_BINARY + \n",
    "                                        cv2.THRESH_OTSU)\n",
    "\n",
    "road = cv2.erode(road, kernel, iterations=5)\n",
    "road = cv2.dilate(road, kernel, iterations=10)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20, 3))\n",
    "\n",
    "\n",
    "ax[0].imshow(marks,cmap='gray')\n",
    "ax[0].set_title('all marks')\n",
    "ax[1].imshow(road,cmap='gray')\n",
    "ax[1].set_title('road segmentation')\n",
    "\n",
    "finall_img=np.zeros_like(top_view)\n",
    "finall_img[road==0]=[100,255,255]\n",
    "\n",
    "cax=cv2.addWeighted(finall_img, 0.5, top_view, 1, 0)\n",
    "\n",
    "cax[marks!=0]=[0,0,255]\n",
    "\n",
    "ax[2].imshow(cv2.cvtColor(cax, cv2.COLOR_BGR2RGB))\n",
    "ax[2].set_title('finall')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bffce7",
   "metadata": {},
   "source": [
    "### Hough lane detaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f7fea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def region_of_interest_road(img):\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    mask = 255*np.ones_like(img)\n",
    "    poly = np.array([[\n",
    "    (500,1080),\n",
    "    (600, 0),\n",
    "    \n",
    "    (1200, 0),\n",
    "    (1300, 1080)]], np.int32)\n",
    "    kernel =np.ones((3, 3),np.uint8)\n",
    "    cv2.fillPoly(mask, poly, (0, 0, 0))\n",
    "#     mask = cv2.erode(mask, kernel, iterations=50)\n",
    "#     mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def region_of_interest_lane(img):\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    mask = np.zeros_like(img)\n",
    "    poly = np.array([[\n",
    "    (500,1000),\n",
    "    (650, 500),\n",
    "    \n",
    "    (1200, 500),\n",
    "    (1400, 1000)]], np.int32)\n",
    "    kernel =np.ones((3, 3),np.uint8)\n",
    "    cv2.fillPoly(mask, poly, (255, 255, 255))\n",
    "#     mask = cv2.erode(mask, kernel, iterations=50)\n",
    "#     mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "\n",
    "alpha=2\n",
    "beta=10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for i in np.arange(1,133,5):\n",
    "img = cv2.imread('IMAGE PATH')\n",
    "mask=img.copy()\n",
    "mask[:int(2*mask.shape[0]/3),:]=0\n",
    "mask[1000:,:]=0\n",
    "top_view=tr_top_view(mask, img_size=(img.shape[1],img.shape[0]), flags=cv2.INTER_LINEAR)   \n",
    "top_view = cv2.convertScaleAbs(top_view, alpha=alpha, beta=beta)\n",
    "kernel = np.array([[0, -1, 0],\n",
    "                   [-1, 5,-1],\n",
    "                   [0, -1, 0]])\n",
    "top_view = cv2.filter2D(src=top_view, ddepth=-1, kernel=kernel)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(20, 20))\n",
    "ax[0].imshow(cv2.cvtColor(top_view, cv2.COLOR_BGR2RGB))\n",
    "ax[0].set_title('top_view')   \n",
    "\n",
    "edges=canny(top_view, 30, 60)\n",
    "kernel =np.ones((3, 3),np.uint8)\n",
    "edges = cv2.erode(edges, kernel, iterations=10)\n",
    "edges = cv2.dilate(edges, kernel, iterations=10)\n",
    "\n",
    "ax[1].imshow(cv2.cvtColor(edges, cv2.COLOR_BGR2RGB))\n",
    "ax[1].set_title('hough') \n",
    "\n",
    "try:\n",
    "    edges = region_of_interest_road(edges)\n",
    "    advlines = cv2.HoughLinesP(edges, 1, np.pi/180, 50, np.array([]), minLineLength=100, maxLineGap=2)\n",
    "    lanes = average_slope_intercept(top_view.copy(),advlines)\n",
    "    lanes=display_advlines(mask.copy(),lanes)\n",
    "\n",
    "    ax[2].imshow(cv2.cvtColor(cv2.addWeighted(lanes, 1, top_view, 0.6, 0), cv2.COLOR_BGR2RGB))\n",
    "    ax[2].set_title('finall hough')\n",
    "except:\n",
    "    ax[2].imshow(cv2.cvtColor(top_view, cv2.COLOR_BGR2RGB))\n",
    "    ax[2].set_title('finall hough')\n",
    "try:\n",
    "    edges=canny(top_view, 25, 50)\n",
    "    edges = region_of_interest_lane(edges)\n",
    "    advlines = cv2.HoughLinesP(edges, 1, np.pi/180, 50, np.array([]), minLineLength=100, maxLineGap=2)\n",
    "    lanes = average_slope_intercept(top_view.copy(),advlines)\n",
    "    lanes=display_advlines(mask.copy(),lanes)\n",
    "\n",
    "    ax[3].imshow(cv2.cvtColor(cv2.addWeighted(lanes, 1, top_view, 0.6, 0), cv2.COLOR_BGR2RGB))\n",
    "    ax[3].set_title('finall hough')\n",
    "except:\n",
    "    ax[3].imshow(cv2.cvtColor(top_view, cv2.COLOR_BGR2RGB))\n",
    "    ax[3].set_title('finall hough')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86ee903",
   "metadata": {},
   "source": [
    "### Traffic Sign Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4664e748",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel =np.ones((3, 3),np.uint8)\n",
    "def region_of_interest(img,is_left):\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    mask = np.zeros_like(img)\n",
    "    \n",
    "    if is_left:\n",
    "        poly = np.array([[\n",
    "        (0,int(0.75*height)),\n",
    "        (0, int(0.3*height)),\n",
    "\n",
    "        (int(width/3), int(0.3*height)),\n",
    "        (int(width/3), int(0.75*height))]], np.int32)\n",
    "        \n",
    "    else:\n",
    "        poly = np.array([[\n",
    "        (int(2*width/3),int(0.75*height)),\n",
    "        (int(2*width/3), int(0.3*height)),\n",
    "\n",
    "        (width, int(0.3*height)),\n",
    "        (width, int(0.75*height))]], np.int32)\n",
    "        \n",
    "    cv2.fillPoly(mask, poly, (255, 255, 255))\n",
    "#     mask = cv2.erode(mask, kernel, iterations=50)\n",
    "#     mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def right_view(img, img_size, flags=cv2.INTER_LINEAR):\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    src = np.float32([(int(2*width/3), int(0.3*height)),     # top-left\n",
    "                       (int(2*width/3),int(0.75*height)),     # bottom-left\n",
    "                       (width, int(0.75*height)),    # bottom-right\n",
    "                       (width, int(0.3*height))])    # top-right\n",
    "\n",
    "\n",
    "    dst = np.float32([(0,0),     # top-left\n",
    "                       (0, img.shape[0]),     # bottom-left\n",
    "                       (img.shape[1], img.shape[0]),    # bottom-right\n",
    "                       (img.shape[1], 0)])\n",
    "\n",
    "    \n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    \n",
    "    return cv2.warpPerspective(img, M, img_size, flags=flags)\n",
    "\n",
    "\n",
    "def canny(img,d,u):\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    kernel = 3\n",
    "    blur = cv2.GaussianBlur(gray,(kernel, kernel),0)\n",
    "    canny = cv2.Canny(blur, d, u)\n",
    "    kernel =np.ones((3, 3),np.uint8)\n",
    "#     canny = cv2.erode(canny, kernel, iterations=5)\n",
    "    canny = cv2.dilate(canny, kernel, iterations=1)\n",
    "\n",
    "    return canny\n",
    "\n",
    "\n",
    "\n",
    "def roi(img):\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    mask = np.zeros_like(img)\n",
    "    \n",
    "\n",
    "    poly = np.array([[\n",
    "    (0,int(0.75*height)),\n",
    "    (0, int(0.3*height)),\n",
    "\n",
    "    (width, int(0.3*height)),\n",
    "    (width, int(0.75*height))]], np.int32)\n",
    "    cv2.fillPoly(mask, poly, (255, 255, 255))\n",
    "#     mask = cv2.erode(mask, kernel, iterations=50)\n",
    "#     mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a0a79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for i in [4,102,143,144,176,177,189,193,251,410,457,1895,1908,1926,1978,2000]:\n",
    "#     print(i)\n",
    "img = cv2.imread('IMAGE PATH')\n",
    "total_view = roi(img)\n",
    "#     total_view=right_view(img, img_size=(img.shape[1],img.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "contrast_total_view = cv2.convertScaleAbs(total_view, alpha=2, beta=25)\n",
    "fig, ax = plt.subplots(1, 4, figsize=(20, 20))\n",
    "plt.subplots_adjust(wspace=0.1)\n",
    "ax[0].imshow(cv2.cvtColor(contrast_total_view, cv2.COLOR_BGR2RGB))\n",
    "ax[0].set_title('orginal image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "\n",
    "\n",
    "canny_marks=canny(contrast_total_view, 50, 80)\n",
    "\n",
    "ax[1].imshow(cv2.cvtColor(canny_marks, cv2.COLOR_BGR2RGB))\n",
    "ax[1].set_title('canny method')\n",
    "ax[1].axis('off')\n",
    "\n",
    "gray = cv2.cvtColor(contrast_total_view, cv2.COLOR_BGR2GRAY)\n",
    "_, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "#     binary = cv2.erode(binary, kernel, iterations=50)\n",
    "ax[2].imshow(binary, cmap='gray')\n",
    "ax[2].set_title('thresh image')\n",
    "\n",
    "\n",
    "contours,_ = cv2.findContours(canny_marks, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for cnt in contours:\n",
    "    # Get convex hull\n",
    "    hull = cv2.convexHull(cnt)\n",
    "\n",
    "    # Get approximate polygon\n",
    "    epsilon = 0.02*cv2.arcLength(hull,True)\n",
    "    approx = cv2.approxPolyDP(hull,epsilon,True)\n",
    "\n",
    "#         if len(approx) == 3:\n",
    "        # Draw triangle\n",
    "#             cv2.drawContours(contrast_total_view,[approx],0,(0,255,0),10)\n",
    "    if len(approx) == 4:\n",
    "        # Draw rectangle\n",
    "        cv2.drawContours(contrast_total_view,[approx],0,(255,0,0),10)\n",
    "\n",
    "ax[3].imshow(cv2.cvtColor(contrast_total_view, cv2.COLOR_BGR2RGB))\n",
    "ax[3].set_title('hough image')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
